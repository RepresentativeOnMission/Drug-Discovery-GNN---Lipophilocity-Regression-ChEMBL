{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pubchempy\n",
        "!pip install rdkit\n",
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQHKgtjQp0tz",
        "outputId": "6e517edd-4380-4dd4-f593-c973768c02c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pubchempy\n",
            "  Downloading PubChemPy-1.0.4.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pubchempy\n",
            "  Building wheel for pubchempy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pubchempy: filename=PubChemPy-1.0.4-py3-none-any.whl size=13820 sha256=6d7571cc175e457ff2c82f6166137af4855560c58db4c39a79f88ff30ebdf306\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/7c/45/18a0671e3c3316966ef7ed9ad2b3f3300a7e41d3421a44e799\n",
            "Successfully built pubchempy\n",
            "Installing collected packages: pubchempy\n",
            "Successfully installed pubchempy-1.0.4\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.3.3-cp310-cp310-manylinux_2_28_x86_64.whl (33.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2024.3.3\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2Hzhiif_-V8"
      },
      "outputs": [],
      "source": [
        "from pandas.plotting import table\n",
        "from rdkit import Chem\n",
        "from sklearn.metrics import r2_score\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import MoleculeNet\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch.nn import Linear\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pubchempy\n",
        "import rdkit\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MoleculeNet(root=\".\", name=\"lipo\")\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axyuGWUTn014",
        "outputId": "408e677c-f657-42b3-8185-4df8f616d141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/Lipophilicity.csv\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "qOA3Yv55tekv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0])\n",
        "print(\"Number of atoms in the first compound of the dataset: \" + str(dataset[0].num_nodes))\n",
        "print(\"Matrix containing the features of each atom of the first compound of the dataset:\")\n",
        "print(dataset[0].x)\n",
        "print(\"Number of edges connecting the atoms of the first compound: \" + str(dataset[0].num_edges))\n",
        "print(\"Adjacency list representing the edges connecting the atoms of the first compound:\")\n",
        "print(dataset[0].edge_index)\n",
        "print(\"Lipophilocity value for the first compound of the dataset: \" + str(dataset[0].y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXr7pP6FtA5j",
        "outputId": "58f6526e-7904-450f-94e0-021585043d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[24, 9], edge_index=[2, 54], edge_attr=[54, 3], smiles='Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14', y=[1, 1])\n",
            "Number of atoms in the first compound of the dataset: 24\n",
            "Matrix containing the features of each atom of the first compound of the dataset:\n",
            "tensor([[ 6,  0,  4,  5,  3,  0,  4,  0,  0],\n",
            "        [ 7,  0,  3,  5,  0,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1],\n",
            "        [ 6,  0,  4,  5,  2,  0,  4,  0,  0],\n",
            "        [ 7,  0,  3,  5,  0,  0,  4,  0,  1],\n",
            "        [ 6,  0,  4,  5,  2,  0,  4,  0,  1],\n",
            "        [ 6,  0,  4,  5,  2,  0,  4,  0,  1],\n",
            "        [ 7,  0,  3,  5,  0,  0,  3,  0,  1],\n",
            "        [ 6,  0,  4,  5,  2,  0,  4,  0,  1],\n",
            "        [ 6,  0,  4,  5,  2,  0,  4,  0,  1],\n",
            "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1],\n",
            "        [17,  0,  1,  5,  0,  0,  4,  0,  0],\n",
            "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1],\n",
            "        [ 7,  0,  2,  5,  0,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  1,  0,  3,  1,  1],\n",
            "        [ 6,  0,  3,  5,  0,  0,  3,  1,  1]])\n",
            "Number of edges connecting the atoms of the first compound: 54\n",
            "Adjacency list representing the edges connecting the atoms of the first compound:\n",
            "tensor([[ 0,  1,  1,  1,  2,  2,  2,  3,  3,  4,  4,  4,  5,  5,  6,  6,  7,  7,\n",
            "          7,  8,  8,  9,  9, 10, 10, 10, 11, 11, 12, 12, 13, 13, 13, 14, 15, 15,\n",
            "         16, 16, 17, 17, 18, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 23],\n",
            "        [ 1,  0,  2, 23,  1,  3, 17,  2,  4,  3,  5,  9,  4,  6,  5,  7,  6,  8,\n",
            "         10,  7,  9,  4,  8,  7, 11, 16, 10, 12, 11, 13, 12, 14, 15, 13, 13, 16,\n",
            "         10, 15,  2, 18, 17, 19, 23, 18, 20, 19, 21, 20, 22, 21, 23,  1, 18, 22]])\n",
            "Lipophilocity value for the first compound of the dataset: tensor([[3.5400]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "**Input:** The model described below takes as input a graph where node information is represented as feature vectors.\n",
        "\n",
        "**Architecture:** This model is composed of 4 consecutive **graph convolutional layers** which are defined as: update($h_{t-1}$, aggregate($\\sum_{v_i \\in N_{v_t}}v_i)$), where **aggregate** on a given node $v_t$ is defined as $\\sum_{v_i \\in N_{v_t}}(\\frac{W*v_i}{degree(v_t)})$, and **update** is defined as the nonlinear tanh function.\n",
        "\n",
        "* Note that Graph Convolutional operations are **permutation equivariant**\n",
        "\n",
        "**Output:** At the end of the network we use both a **global avg pooling (GAP)** and a **global max pooling (GMP)**, concatenate them and feed them to a lienar layer which outputs a regression value.\n",
        "\n",
        "* Note that **GAP and GMP** are both **permutation invariant** operations"
      ],
      "metadata": {
        "id": "4E08Gnv7z04I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 64\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        # Init parent\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "\n",
        "        # GCN layers\n",
        "        self.initial_conv = GCNConv(data.num_features, embedding_size)\n",
        "        self.conv1 = GCNConv(embedding_size, embedding_size)\n",
        "        self.conv2 = GCNConv(embedding_size, embedding_size)\n",
        "        self.conv3 = GCNConv(embedding_size, embedding_size)\n",
        "\n",
        "        # Output layer\n",
        "        self.out = Linear(embedding_size*2, 1)\n",
        "\n",
        "    def forward(self, x, edge_index, batch_index):\n",
        "        # First Conv layer\n",
        "        hidden = self.initial_conv(x, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "\n",
        "        # Conv layers\n",
        "        hidden = self.conv1(hidden, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "        hidden = self.conv2(hidden, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "        hidden = self.conv3(hidden, edge_index)\n",
        "        hidden = F.tanh(hidden)\n",
        "\n",
        "        # Global Pooling (stack different aggregations)\n",
        "        hidden = torch.cat([gmp(hidden, batch_index),\n",
        "                            gap(hidden, batch_index)], dim=1)\n",
        "\n",
        "        # Classifier (Linear).\n",
        "        out = self.out(hidden)\n",
        "\n",
        "        return out, hidden\n",
        "\n",
        "model = GCN()\n",
        "print(model)\n",
        "print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0L147Luvhj6",
        "outputId": "f614a6a8-3932-48ed-e059-f028d6f497a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN(\n",
            "  (initial_conv): GCNConv(9, 64)\n",
            "  (conv1): GCNConv(64, 64)\n",
            "  (conv2): GCNConv(64, 64)\n",
            "  (conv3): GCNConv(64, 64)\n",
            "  (out): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "Number of parameters:  13249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAIN/TEST DATALOADER\n"
      ],
      "metadata": {
        "id": "h8SeR7hY-GAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Data loader\n",
        "data_size = len(dataset)\n",
        "NUM_GRAPHS_PER_BATCH = 64\n",
        "NUM_EPOCHS = 900\n",
        "\n",
        "torch.manual_seed(12345)\n",
        "\n",
        "#randomize and split the data\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "train_dataset = dataset[:int(data_size * 0.8)]\n",
        "test_dataset = dataset[int(data_size * 0.8):]\n",
        "\n",
        "loader = DataLoader(train_dataset, batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=NUM_GRAPHS_PER_BATCH, shuffle=False)\n",
        "\n",
        "print('\\n======== data distribution =======\\n')\n",
        "print(\"Size of training data: {} graphs\".format(len(train_dataset)))\n",
        "print(\"Size of testing data: {} graphs\".format(len(test_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Byz5pJl7l4W",
        "outputId": "9b9f088d-bf11-4950-bd78-0a7dfee4d433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== data distribution =======\n",
            "\n",
            "Size of training data: 3360 graphs\n",
            "Size of testing data: 840 graphs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ],
      "metadata": {
        "id": "2PG8o2e4-WhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Root mean squared error\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0007)\n",
        "\n",
        "# Calculate accuracy r2\n",
        "def r2_accuracy(pred_y, y):\n",
        "    score = r2_score(y, pred_y)\n",
        "    return round(score, 2)*100\n",
        "\n",
        "# Data generated\n",
        "embeddings = []\n",
        "losses = []\n",
        "accuracies = []\n",
        "outputs = []\n",
        "targets = []\n",
        "\n",
        "# Use GPU for training, if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "def train(data):\n",
        "    # Enumerate over the data\n",
        "    for batch in loader:\n",
        "      # Use GPU\n",
        "      batch.to(device)\n",
        "      # Reset gradients\n",
        "      optimizer.zero_grad()\n",
        "      # Passing the node features and the connection info\n",
        "      pred, embedding = model(batch.x.float(), batch.edge_index, batch.batch)\n",
        "      # Calculating the loss and gradients\n",
        "      loss = loss_fn(pred, batch.y)\n",
        "      acc = r2_accuracy(pred.cpu().detach().numpy(), batch.cpu().y.detach().numpy())\n",
        "\n",
        "      loss.backward()\n",
        "      # Update using the gradients\n",
        "      optimizer.step()\n",
        "    return loss, acc, pred, batch.y, embedding\n",
        "\n",
        "print('\\n======== Starting training ... =======\\n')\n",
        "start_time = time.time()\n",
        "\n",
        "losses = []\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    loss, acc, pred, target, h = train(data)\n",
        "    losses.append(loss)\n",
        "    accuracies.append(acc)\n",
        "    outputs.append(pred)\n",
        "    targets.append(target)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "      # print(f\"Epoch {epoch} | Train Loss {loss}\")\n",
        "      print(f'Epoch {epoch:>3} | Loss: {loss:.5f} | Acc: {acc:.2f}%')\n",
        "\n",
        "print(\"\\nTraining done!\\n\")\n",
        "elapsed = time.time() - start_time\n",
        "minutes_e = elapsed//60\n",
        "print(\"--- training took:  %s minutes ---\" % (minutes_e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLA_l_8b-VU5",
        "outputId": "625d6513-db0d-41c5-a389-ba7a4722b2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Starting training ... =======\n",
            "\n",
            "Epoch   0 | Loss: 1.21428 | Acc: -1.00%\n",
            "Epoch 100 | Loss: 0.57189 | Acc: 62.00%\n",
            "Epoch 200 | Loss: 0.31194 | Acc: 70.00%\n",
            "Epoch 300 | Loss: 0.21917 | Acc: 86.00%\n",
            "Epoch 400 | Loss: 0.16295 | Acc: 89.00%\n",
            "Epoch 500 | Loss: 0.22088 | Acc: 85.00%\n",
            "Epoch 600 | Loss: 0.27331 | Acc: 85.00%\n",
            "Epoch 700 | Loss: 0.09960 | Acc: 92.00%\n",
            "Epoch 800 | Loss: 0.10423 | Acc: 90.00%\n",
            "\n",
            "Training done!\n",
            "\n",
            "--- training took:  9.0 minutes ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# One batch prediction\n",
        "test_batch = next(iter(test_loader))\n",
        "with torch.no_grad():\n",
        "    test_batch.to(device)\n",
        "    pred, embed = model(test_batch.x.float(), test_batch.edge_index, test_batch.batch)\n",
        "    df = pd.DataFrame()\n",
        "    df[\"y\"] = test_batch.y.tolist()\n",
        "    df[\"y_pred\"] = pred.tolist()\n",
        "df[\"real\"] = df[\"y\"].apply(lambda row: row[0])\n",
        "df[\"pred\"] = df[\"y_pred\"].apply(lambda row: row[0])\n",
        "df.head()\n",
        "\n",
        "test_acc = r2_accuracy(df[\"real\"], df[\"pred\"])\n",
        "\n",
        "print(\"Test accuracy is {}%\".format(round(test_acc, 2) ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ5FrvtpeneI",
        "outputId": "c0d0b1ec-8aa5-47b9-e50e-9d4a2472e8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is 32.0%\n"
          ]
        }
      ]
    }
  ]
}